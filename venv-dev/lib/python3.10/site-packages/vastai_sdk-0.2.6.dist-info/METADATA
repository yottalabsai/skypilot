Metadata-Version: 2.4
Name: vastai-sdk
Version: 0.2.6
Summary: SDK for Vast.ai GPU Cloud Service
License-File: LICENSE
Author: Chris McKenzie
Author-email: chris@vast.ai
Requires-Python: >=3.9
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: 3.14
Requires-Dist: aiodns (>=3.6.0)
Requires-Dist: aiohttp (==3.10.1)
Requires-Dist: asyncio
Requires-Dist: borb (>=2.1.25,<2.2.0)
Requires-Dist: jsonschema (>=3.2)
Requires-Dist: pycares (==4.11.0)
Requires-Dist: pyparsing
Requires-Dist: python-dateutil
Requires-Dist: pytz
Requires-Dist: requests (>=2.25)
Requires-Dist: urllib3
Requires-Dist: xdg (>=1.0.0)
Project-URL: Homepage, https://vast.ai
Project-URL: Repository, https://github.com/vast-ai/vast-sdk
Project-URL: Source, https://github.com/vast-ai/vast-sdk
Description-Content-Type: text/markdown

# Vast.ai Python SDK
[![PyPI version](https://badge.fury.io/py/vastai-sdk.svg)](https://badge.fury.io/py/vastai-sdk)

The official Vast.ai SDK pip package.

## Install
```bash
pip install vastai-sdk
```
## Examples

NOTE: Ensure your Vast.ai API key is set in your working environment as `VAST_API_KEY`. Alternatively, you may pass the API key in as a parameter to either client.

### Using the VastAI CLI client

1. Create the client
```python
from vastai import VastAI
vastai = VastAI() # or, VastAI("YOUR_API_KEY")
```
2. Run commands
```python
vastai.search_offers()
```
3. Get help
```python
help(v.create_instances)
```

### Using the Serverless client

1. Create the client
```python
from vastai import Serverless
serverless = Serverless() # or, Serverless("YOUR_API_KEY")
```
2. Get an endpoint
```python
endpoint = await serverless.get_endpoint("my-endpoint")
```
3. Make a request
```python
request_body = {
                "input" : {
                    "model": "Qwen/Qwen3-8B",
                    "prompt" : "Who are you?",
                    "max_tokens" : 100,
                    "temperature" : 0.7
                }
            }
response = await serverless.request("/v1/completions", request_body)
```
4. Read the response
```python
text = response["response"]["choices"][0]["text"]
print(text)
```

Find more examples in the `examples` directory

