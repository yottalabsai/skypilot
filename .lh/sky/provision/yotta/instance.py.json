{
    "sourceFile": "sky/provision/yotta/instance.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1768482813898,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1768482813898,
            "name": "Commit-0",
            "content": "\"\"\"Yotta instance provisioning.\"\"\"\nimport time\nfrom typing import Any, Dict, List, Optional\n\nfrom sky import sky_logging\nfrom sky.provision import common\nfrom sky.provision.yotta import yotta_utils\nfrom sky.provision.yotta.yotta_utils import PodStatusEnum\nfrom sky.provision.yotta.yotta_utils import yotta_client\nfrom sky.utils import common_utils\nfrom sky.utils import resources_utils\nfrom sky.utils import status_lib\nfrom sky.utils import ux_utils\n\nPOLL_INTERVAL = 5\nQUERY_PORTS_TIMEOUT_SECONDS = 30\n\nlogger = sky_logging.init_logger(__name__)\n\n\ndef _filter_instances(cluster_name_on_cloud: str,\n                      status_filters: Optional[List[PodStatusEnum]],\n                      head_only: bool = False) -> Dict[str, Any]:\n\n    instances = yotta_client.list_instances(cluster_name_on_cloud)\n    possible_names = [f'{cluster_name_on_cloud}-head']\n    if not head_only:\n        possible_names.append(f'{cluster_name_on_cloud}-worker')\n\n    filtered_instances = {}\n    for instance_id, instance in instances.items():\n        status = instance.get('status')\n        try:\n            instance_status = PodStatusEnum(status)\n        except ValueError:\n            logger.warning(f'Unknown pod status: {status}')\n            continue\n        if (status_filters is not None and\n                instance_status not in status_filters):\n            continue\n        if instance.get('name') in possible_names:\n            filtered_instances[instance_id] = instance\n    return filtered_instances\n\n\ndef _get_head_instance_id(instances: Dict[str, Any]) -> Optional[str]:\n    head_instance_id = None\n    for inst_id, inst in instances.items():\n        if inst['name'].endswith('-head'):\n            head_instance_id = inst_id\n            break\n    return head_instance_id\n\n\ndef run_instances(region: str, cluster_name_on_cloud: str,\n                  config: common.ProvisionConfig) -> common.ProvisionRecord:\n    \"\"\"Runs instances for the given cluster.\"\"\"\n\n    pending_status = [PodStatusEnum.INITIALIZE]\n\n    while True:\n        instances = _filter_instances(cluster_name_on_cloud, pending_status)\n        if not instances:\n            break\n        logger.info(f'Waiting for {len(instances)} instances to be ready.')\n        time.sleep(POLL_INTERVAL)\n    exist_instances = _filter_instances(cluster_name_on_cloud,\n                                        [PodStatusEnum.RUNNING])\n    head_instance_id = _get_head_instance_id(exist_instances)\n\n    to_start_count = config.count - len(exist_instances)\n    if to_start_count < 0:\n        raise RuntimeError(\n            f'Cluster {cluster_name_on_cloud} already has '\n            f'{len(exist_instances)} nodes, but {config.count} are required.')\n    if to_start_count == 0:\n        if head_instance_id is None:\n            raise RuntimeError(\n                f'Cluster {cluster_name_on_cloud} has no head node.')\n        logger.info(f'Cluster {cluster_name_on_cloud} already has '\n                    f'{len(exist_instances)} nodes, no need to start more.')\n        return common.ProvisionRecord(\n            provider_name='yotta',\n            cluster_name=cluster_name_on_cloud,\n            region=region,\n            zone=config.provider_config['availability_zone'],\n            head_instance_id=head_instance_id,\n            resumed_instance_ids=[],\n            created_instance_ids=[])\n\n    created_instance_ids = []\n\n    for _ in range(to_start_count):\n        node_type = 'head' if head_instance_id is None else 'worker'\n        try:\n            instance_id = yotta_client.launch(\n                cluster_name=cluster_name_on_cloud,\n                node_type=node_type,\n                instance_type=config.node_config['InstanceType'],\n                region=region,\n                zone=config.provider_config['availability_zone'],\n                image_name=config.node_config['ImageId'],\n                ports=config.ports_to_open_on_launch,\n                public_key=config.node_config['PublicKey'],\n                ssh_user=config.authentication_config['ssh_user'],\n            )\n        except Exception as e:  # pylint: disable=broad-except\n            logger.warning(f'run_instances error: {e}')\n            raise\n        logger.info(f'Launched instance {instance_id}.')\n        created_instance_ids.append(instance_id)\n        if head_instance_id is None:\n            head_instance_id = instance_id\n\n    # Wait for instances to be ready.\n    while True:\n        instances = _filter_instances(cluster_name_on_cloud,\n                                      [PodStatusEnum.RUNNING])\n        ready_instance_cnt = 0\n        for instance_id, instance in instances.items():\n            port = yotta_utils.get_ssh_port(instance)\n            if port is not None and port.get('healthy'):\n                ready_instance_cnt += 1\n        logger.info('Waiting for instances to be ready: '\n                    f'({ready_instance_cnt}/{config.count}).')\n        if ready_instance_cnt == config.count:\n            break\n\n        time.sleep(POLL_INTERVAL)\n    assert head_instance_id is not None, 'head_instance_id should not be None'\n    return common.ProvisionRecord(\n        provider_name='yotta',\n        cluster_name=cluster_name_on_cloud,\n        region=region,\n        zone=config.provider_config['availability_zone'],\n        head_instance_id=head_instance_id,\n        resumed_instance_ids=[],\n        created_instance_ids=created_instance_ids)\n\n\ndef wait_instances(region: str, cluster_name_on_cloud: str,\n                   state: Optional[status_lib.ClusterStatus]) -> None:\n    del region, cluster_name_on_cloud, state\n\n\ndef stop_instances(\n    cluster_name_on_cloud: str,\n    provider_config: Optional[Dict[str, Any]] = None,\n    worker_only: bool = False,\n) -> None:\n    raise NotImplementedError()\n\n\ndef terminate_instances(\n    cluster_name_on_cloud: str,\n    provider_config: Optional[Dict[str, Any]] = None,\n    worker_only: bool = False,\n) -> None:\n    \"\"\"See sky/provision/__init__.py\"\"\"\n    del provider_config  # unused\n    instances = _filter_instances(cluster_name_on_cloud, None)\n    for inst_id, inst in instances.items():\n        logger.debug(f'Terminating instance {inst_id}: {inst}')\n        if worker_only and inst['name'].endswith('-head'):\n            continue\n        try:\n            yotta_client.terminate_instances(int(inst_id))\n        except Exception as e:  # pylint: disable=broad-except\n            with ux_utils.print_exception_no_traceback():\n                raise RuntimeError(\n                    f'Failed to terminate instance {inst_id}: '\n                    f'{common_utils.format_exception(e, use_bracket=False)}'\n                ) from e\n\n\ndef get_cluster_info(\n        region: str,\n        cluster_name_on_cloud: str,\n        provider_config: Optional[Dict[str, Any]] = None) -> common.ClusterInfo:\n    del region  # unused\n    running_instances = _filter_instances(cluster_name_on_cloud,\n                                          [PodStatusEnum.RUNNING])\n    instances: Dict[str, List[common.InstanceInfo]] = {}\n    head_instance_id = None\n    for instance_id, instance_info in running_instances.items():\n        port = yotta_utils.get_ssh_port(instance_info)\n        external_ip = port.get('host')\n        internal_ip = port.get('privateHost')\n        instances[instance_id] = [\n            common.InstanceInfo(\n                instance_id=instance_id,\n                internal_ip=internal_ip,\n                external_ip=external_ip,\n                ssh_port=port.get('proxyPort'),\n                tags={},\n            )\n        ]\n        if instance_info['name'].endswith('-head'):\n            head_instance_id = instance_id\n    return common.ClusterInfo(\n        instances=instances,\n        head_instance_id=head_instance_id,\n        provider_name='yotta',\n        provider_config=provider_config,\n        # Ray cluster uses internal IPs for inter-node communication\n        # External IPs are only used for SSH access from outside\n        custom_ray_options={'use_external_ip': False},\n    )\n\n\ndef query_instances(\n    cluster_name_on_cloud: str,\n    provider_config: Optional[Dict[str, Any]] = None,\n    non_terminated_only: bool = True,\n) -> Dict[str, Optional[status_lib.ClusterStatus]]:\n    \"\"\"See sky/provision/__init__.py\"\"\"\n    assert provider_config is not None, (cluster_name_on_cloud, provider_config)\n    instances = _filter_instances(cluster_name_on_cloud, None)\n    status_map = {\n        PodStatusEnum.INITIALIZE: status_lib.ClusterStatus.INIT,\n        PodStatusEnum.RUNNING: status_lib.ClusterStatus.UP,\n        PodStatusEnum.TERMINATING: status_lib.ClusterStatus.UP,\n        PodStatusEnum.TERMINATED: status_lib.ClusterStatus.STOPPED,\n        PodStatusEnum.FAILED: status_lib.ClusterStatus.STOPPED,\n        # not support pause just mapping status\n        PodStatusEnum.PAUSING: status_lib.ClusterStatus.UP,\n        PodStatusEnum.PAUSED: status_lib.ClusterStatus.STOPPED,\n    }\n    statuses: Dict[str, Optional[status_lib.ClusterStatus]] = {}\n    for inst_id, instance in instances.items():\n        status = status_map[PodStatusEnum(instance.get('status'))]\n        if non_terminated_only and status is None:\n            continue\n        statuses[inst_id] = status\n    return statuses\n\n\ndef cleanup_ports(\n    cluster_name_on_cloud: str,\n    ports: List[str],\n    provider_config: Optional[Dict[str, Any]] = None,\n) -> None:\n    del cluster_name_on_cloud, ports, provider_config  # Unused.\n\n\ndef query_ports(\n    cluster_name_on_cloud: str,\n    ports: List[str],\n    head_ip: Optional[str] = None,\n    provider_config: Optional[Dict[str, Any]] = None,\n) -> Dict[int, List[common.Endpoint]]:\n    \"\"\"See sky/provision/__init__.py\"\"\"\n    del head_ip, provider_config  # Unused.\n    # RunPod ports sometimes take a while to be ready.\n    start_time = time.time()\n    ports_to_query = resources_utils.port_ranges_to_set(ports)\n    while True:\n        instances = _filter_instances(cluster_name_on_cloud,\n                                      None,\n                                      head_only=True)\n        # don't support multiple instances\n        assert len(instances) <= 1\n        # It is possible that the instance is terminated on console by\n        # the user. In this case, the instance will not be found, and we\n        # should return an empty dict.\n        if not instances:\n            return {}\n        head_instance = list(instances.values())[0]\n        ready_ports: Dict[int, List[common.Endpoint]] = {\n            port: [common.SocketEndpoint(**endpoint)]\n            for port, endpoint in head_instance['port2endpoint'].items()\n            if port in ports_to_query\n        }\n        not_ready_ports = ports_to_query - set(ready_ports.keys())\n        if not not_ready_ports:\n            return ready_ports\n        if time.time() - start_time > QUERY_PORTS_TIMEOUT_SECONDS:\n            logger.warning(f'Querying ports {ports} timed out. Ports '\n                           f'{not_ready_ports} are not ready.')\n            return ready_ports\n        time.sleep(1)\n"
        }
    ]
}