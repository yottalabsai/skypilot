{
    "sourceFile": "sky/authentication.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1768543303318,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1768543349242,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -380,9 +380,8 @@\n \n     return configure_ssh_info(config)\n \n \n-<<<<<<< HEAD\n # ---------------------------------- Yotta ---------------------------------- #\n def setup_yotta_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n     \"\"\"Sets up SSH authentication for Yotta.\n     - Generates a new SSH key pair if one does not exist.\n"
                }
            ],
            "date": 1768543303318,
            "name": "Commit-0",
            "content": "\"\"\"Module to enable a single SkyPilot key for all VMs in each cloud.\n\nThe `setup_<cloud>_authentication` functions will be called on every cluster\nprovisioning request.\n\nSpecifically, after the ray yaml template file `<cloud>-ray.yml.j2` is filled in\nwith resource specific information, these functions are called with the filled\nin ray yaml config as input,\n1. Replace the placeholders in the ray yaml file `skypilot:ssh_user` and\n   `skypilot:ssh_public_key_content` with the actual username and public key\n   content, i.e., `configure_ssh_info`.\n2. Setup the `authorized_keys` on the remote VM with the public key content,\n   by cloud-init or directly using cloud provider's API.\n\nThe local machine's public key should not be uploaded to the remote VM, because\nit will cause private/public key pair mismatch when the user tries to launch new\nVM from that remote VM using SkyPilot, e.g., the node is used as a jobs\ncontroller. (Lambda cloud is an exception, due to the limitation of the cloud\nprovider. See the comments in setup_lambda_authentication)\n\"\"\"\nimport copy\nimport os\nimport re\nimport socket\nimport subprocess\nimport sys\nfrom typing import Any, Dict\nimport uuid\n\nimport colorama\n\nfrom sky import clouds\nfrom sky import exceptions\nfrom sky import sky_logging\nfrom sky.adaptors import common as adaptors_common, yotta\nfrom sky.adaptors import gcp\nfrom sky.adaptors import ibm\nfrom sky.adaptors import runpod\nfrom sky.adaptors import seeweb as seeweb_adaptor\nfrom sky.adaptors import shadeform as shadeform_adaptor\nfrom sky.adaptors import vast\nfrom sky.provision.fluidstack import fluidstack_utils\nfrom sky.provision.kubernetes import utils as kubernetes_utils\nfrom sky.provision.lambda_cloud import lambda_utils\nfrom sky.provision.yotta.yotta_utils import yotta_client\nfrom sky.provision.primeintellect import utils as primeintellect_utils\nfrom sky.utils import auth_utils\nfrom sky.utils import common_utils\nfrom sky.utils import subprocess_utils\nfrom sky.utils import ux_utils\nfrom sky.utils import yaml_utils\n\nlogger = sky_logging.init_logger(__name__)\n\n# TODO: Should tolerate if gcloud is not installed. Also,\n# https://pypi.org/project/google-api-python-client/ recommends\n# using Cloud Client Libraries for Python, where possible, for new code\n# development.\n\n\ndef configure_ssh_info(config: Dict[str, Any]) -> Dict[str, Any]:\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    with open(public_key_path, 'r', encoding='utf-8') as f:\n        public_key = f.read().strip()\n    config_str = yaml_utils.dump_yaml_str(config)\n    config_str = config_str.replace('skypilot:ssh_user',\n                                    config['auth']['ssh_user'])\n    config_str = config_str.replace('skypilot:ssh_public_key_content',\n                                    public_key)\n    config = yaml_utils.safe_load(config_str)\n    return config\n\n\ndef parse_gcp_project_oslogin(project):\n    \"\"\"Helper function to parse GCP project metadata.\"\"\"\n    common_metadata = project.get('commonInstanceMetadata', {})\n    if not isinstance(common_metadata, dict):\n        common_metadata = {}\n\n    metadata_items = common_metadata.get('items', [])\n    if not isinstance(metadata_items, list):\n        metadata_items = []\n\n    project_oslogin = next(\n        (item for item in metadata_items\n         if isinstance(item, dict) and item.get('key') == 'enable-oslogin'),\n        {}).get('value', 'False')\n\n    return project_oslogin\n\n\n# Snippets of code inspired from\n# https://github.com/ray-project/ray/blob/master/python/ray/autoscaler/_private/gcp/config.py\n# Takes in config, a yaml dict and outputs a postprocessed dict\n# TODO(weilin): refactor the implementation to incorporate Ray autoscaler to\n# avoid duplicated codes.\n# Retry for the GCP as sometimes there will be connection reset by peer error.\n@common_utils.retry\ndef setup_gcp_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    config = copy.deepcopy(config)\n\n    project_id = config['provider']['project_id']\n    compute = gcp.build('compute',\n                        'v1',\n                        credentials=None,\n                        cache_discovery=False)\n\n    try:\n        project = compute.projects().get(project=project_id).execute()\n    except gcp.http_error_exception() as e:\n        # Can happen for a new project where Compute Engine API is disabled.\n        #\n        # Example message:\n        # 'Compute Engine API has not been used in project 123456 before\n        # or it is disabled. Enable it by visiting\n        # https://console.developers.google.com/apis/api/compute.googleapis.com/overview?project=123456\n        # then retry. If you enabled this API recently, wait a few minutes for\n        # the action to propagate to our systems and retry.'\n        if ' API has not been used in project' in e.reason:\n            match = re.fullmatch(r'(.+)(https://.*project=\\d+) (.+)', e.reason)\n            if match is None:\n                raise  # This should not happen.\n            yellow = colorama.Fore.YELLOW\n            reset = colorama.Style.RESET_ALL\n            bright = colorama.Style.BRIGHT\n            dim = colorama.Style.DIM\n            logger.error(\n                f'{yellow}Certain GCP APIs are disabled for the GCP project '\n                f'{project_id}.{reset}')\n            logger.error('Details:')\n            logger.error(f'{dim}{match.group(1)}{reset}\\n'\n                         f'{dim}    {match.group(2)}{reset}\\n'\n                         f'{dim}{match.group(3)}{reset}')\n            logger.error(\n                f'{yellow}To fix, enable these APIs by running:{reset} '\n                f'{bright}sky check{reset}')\n            sys.exit(1)\n        else:\n            raise\n    except gcp.auth_error_exception() as e:\n        raise exceptions.InvalidCloudCredentials(\n            f'{common_utils.format_exception(e)}')\n    except socket.timeout:\n        logger.error('Socket timed out when trying to get the GCP project. '\n                     'Please check your network connection.')\n        raise\n\n    project_oslogin = parse_gcp_project_oslogin(project)\n    if project_oslogin.lower() == 'true':\n        logger.info(\n            f'OS Login is enabled for GCP project {project_id}. Running '\n            'additional authentication steps.')\n\n        # Try to get the os-login user from `gcloud`, as this is the most\n        # accurate way to figure out how this gcp user is meant to log in.\n        proc = subprocess.run(\n            'gcloud compute os-login describe-profile --format yaml',\n            shell=True,\n            stdout=subprocess.PIPE,\n            check=False)\n        os_login_username = None\n        if proc.returncode == 0:\n            try:\n                profile = yaml_utils.safe_load(proc.stdout)\n                username = profile['posixAccounts'][0]['username']\n                if username:\n                    os_login_username = username\n            except Exception as e:  # pylint: disable=broad-except\n                logger.debug('Failed to parse gcloud os-login profile.\\n'\n                             f'{common_utils.format_exception(e)}')\n                pass\n\n        if os_login_username is None:\n            # As a fallback, read the account information from the credential\n            # file. This works most of the time, but fails if the user's\n            # os-login username is not a straightforward translation of their\n            # email address, for example because their email address changed\n            # within their google workspace after the os-login credentials\n            # were established.\n            config_path = os.path.expanduser(clouds.gcp.GCP_CONFIG_PATH)\n            with open(config_path, 'r', encoding='utf-8') as infile:\n                for line in infile:\n                    if line.startswith('account'):\n                        account = line.split('=')[1].strip()\n                        break\n                else:\n                    with ux_utils.print_exception_no_traceback():\n                        raise RuntimeError(\n                            'GCP authentication failed, as the oslogin is '\n                            f'enabled but the file {config_path} does not '\n                            'contain the account information.')\n            os_login_username = account.replace('@', '_').replace('.', '_')\n        config['auth']['ssh_user'] = os_login_username\n\n        # Add ssh key to GCP with oslogin\n        subprocess.run(\n            'gcloud compute os-login ssh-keys add '\n            f'--key-file={public_key_path}',\n            check=True,\n            shell=True,\n            stdout=subprocess.DEVNULL)\n        # Enable ssh port for all the instances\n        enable_ssh_cmd = ('gcloud compute firewall-rules create '\n                          'allow-ssh-ingress-from-iap '\n                          '--direction=INGRESS '\n                          '--action=allow '\n                          '--rules=tcp:22 '\n                          '--source-ranges=0.0.0.0/0')\n        proc = subprocess.run(enable_ssh_cmd,\n                              check=False,\n                              shell=True,\n                              stdout=subprocess.DEVNULL,\n                              stderr=subprocess.PIPE)\n        if proc.returncode != 0 and 'already exists' not in proc.stderr.decode(\n                'utf-8'):\n            subprocess_utils.handle_returncode(proc.returncode, enable_ssh_cmd,\n                                               'Failed to enable ssh port.',\n                                               proc.stderr.decode('utf-8'))\n    return configure_ssh_info(config)\n\n\ndef setup_lambda_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n\n    auth_utils.get_or_generate_keys()\n\n    # Ensure ssh key is registered with Lambda Cloud\n    lambda_client = lambda_utils.LambdaCloudClient()\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    with open(public_key_path, 'r', encoding='utf-8') as f:\n        public_key = f.read().strip()\n    prefix = f'sky-key-{common_utils.get_user_hash()}'\n    name, exists = lambda_client.get_unique_ssh_key_name(prefix, public_key)\n    if not exists:\n        lambda_client.register_ssh_key(name, public_key)\n\n    config['auth']['remote_key_name'] = name\n    return config\n\n\ndef setup_ibm_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\" registers keys if they do not exist in sky folder\n    and updates config file.\n    keys default location: '~/.ssh/sky-key' and '~/.ssh/sky-key.pub'\n    \"\"\"\n    private_key_path, _ = auth_utils.get_or_generate_keys()\n\n    def _get_unique_key_name():\n        suffix_len = 10\n        return f'skypilot-key-{str(uuid.uuid4())[:suffix_len]}'\n\n    client = ibm.client(region=config['provider']['region'])\n    resource_group_id = config['provider']['resource_group_id']\n\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    with open(os.path.abspath(os.path.expanduser(public_key_path)),\n              'r',\n              encoding='utf-8') as file:\n        ssh_key_data = file.read().strip()\n    # pylint: disable=E1136\n    try:\n        res = client.create_key(public_key=ssh_key_data,\n                                name=_get_unique_key_name(),\n                                resource_group={\n                                    'id': resource_group_id\n                                },\n                                type='rsa').get_result()\n        vpc_key_id = res['id']\n        logger.debug(f'Created new key: {res[\"name\"]}')\n\n    except ibm.ibm_cloud_sdk_core.ApiException as e:\n        if 'Key with fingerprint already exists' in e.message:\n            for key in client.list_keys().result['keys']:\n                if (ssh_key_data in key['public_key'] or\n                        key['public_key'] in ssh_key_data):\n                    vpc_key_id = key['id']\n                    logger.debug(f'Reusing key:{key[\"name\"]}, '\n                                 f'matching existing public key.')\n                    break\n        elif 'Key with name already exists' in e.message:\n            raise Exception(\"\"\"a key with chosen name\n                already registered in the specified region\"\"\") from e\n        else:\n            raise Exception('Failed to register a key') from e\n\n    config['auth']['ssh_private_key'] = private_key_path\n\n    for node_type in config['available_node_types']:\n        config['available_node_types'][node_type]['node_config'][\n            'key_id'] = vpc_key_id\n    return config\n\n\ndef setup_kubernetes_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n    context = kubernetes_utils.get_context_from_config(config['provider'])\n    namespace = kubernetes_utils.get_namespace_from_config(config['provider'])\n    private_key_path, _ = auth_utils.get_or_generate_keys()\n    # Using `kubectl port-forward` creates a direct tunnel to the pod and\n    # does not require a ssh jump pod.\n    kubernetes_utils.check_port_forward_mode_dependencies()\n    # TODO(romilb): This can be further optimized. Instead of using the\n    #   head node as a jump pod for worker nodes, we can also directly\n    #   set the ssh_target to the worker node. However, that requires\n    #   changes in the downstream code to return a mapping of node IPs to\n    #   pod names (to be used as ssh_target) and updating the upstream\n    #   SSHConfigHelper to use a different ProxyCommand for each pod.\n    #   This optimization can reduce SSH time from ~0.35s to ~0.25s, tested\n    #   on GKE.\n    pod_name = config['cluster_name'] + '-head'\n    ssh_proxy_cmd = kubernetes_utils.get_ssh_proxy_command(\n        pod_name,\n        private_key_path=private_key_path,\n        context=context,\n        namespace=namespace)\n    config['auth']['ssh_proxy_command'] = ssh_proxy_cmd\n    config['auth']['ssh_private_key'] = private_key_path\n\n    # Add the user's public key to the SkyPilot cluster.\n    return configure_ssh_info(config)\n\n\n# ---------------------------------- RunPod ---------------------------------- #\ndef setup_runpod_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Sets up SSH authentication for RunPod.\n    - Generates a new SSH key pair if one does not exist.\n    - Adds the public SSH key to the user's RunPod account.\n    \"\"\"\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    with open(public_key_path, 'r', encoding='UTF-8') as pub_key_file:\n        public_key = pub_key_file.read().strip()\n        runpod.runpod.cli.groups.ssh.functions.add_ssh_key(public_key)\n\n    return configure_ssh_info(config)\n\n\ndef setup_vast_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Sets up SSH authentication for Vast.\n    - Generates a new SSH key pair if one does not exist.\n    - Adds the public SSH key to the user's Vast account.\n    \"\"\"\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    with open(public_key_path, 'r', encoding='UTF-8') as pub_key_file:\n        public_key = pub_key_file.read().strip()\n        current_key_list = vast.vast().show_ssh_keys()  # pylint: disable=assignment-from-no-return\n        # Only add an ssh key if it hasn't already been added\n        if not any(x['public_key'] == public_key for x in current_key_list):\n            vast.vast().create_ssh_key(ssh_key=public_key)\n\n    config['auth']['ssh_public_key'] = public_key_path\n    return configure_ssh_info(config)\n\n\ndef setup_fluidstack_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n\n    _, public_key_path = auth_utils.get_or_generate_keys()\n\n    client = fluidstack_utils.FluidstackClient()\n    public_key = None\n    with open(public_key_path, 'r', encoding='utf-8') as f:\n        public_key = f.read()\n    client.get_or_add_ssh_key(public_key)\n    config['auth']['ssh_public_key'] = public_key_path\n    return configure_ssh_info(config)\n\n\ndef setup_hyperbolic_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Sets up SSH authentication for Hyperbolic.\"\"\"\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    with open(public_key_path, 'r', encoding='utf-8') as f:\n        public_key = f.read().strip()\n\n    # TODO: adjust below to use public_keys instead of\n    # public_key once backwards-compatibility is no longer required\n    config['publicKey'] = public_key\n\n    # Set up auth section for Ray template\n    config.setdefault('auth', {})\n    config['auth']['ssh_user'] = 'ubuntu'\n    config['auth']['ssh_public_key'] = public_key_path\n\n    return configure_ssh_info(config)\n\n\n<<<<<<< HEAD\n# ---------------------------------- Yotta ---------------------------------- #\ndef setup_yotta_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Sets up SSH authentication for Yotta.\n    - Generates a new SSH key pair if one does not exist.\n    - Adds the public SSH key to the user's Yotta account.\n    \"\"\"\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    with open(public_key_path, 'r', encoding='UTF-8') as pub_key_file:\n        public_key = pub_key_file.read().strip()\n        yotta_client.get_or_add_ssh_key(public_key)\n\n    config['auth']['ssh_public_key'] = public_key_path\n    return configure_ssh_info(config)\n\n\ndef setup_shadeform_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Sets up SSH authentication for Shadeform.\n    - Generates a new SSH key pair if one does not exist.\n    - Adds the public SSH key to the user's Shadeform account.\n\n    Note: This assumes there is a Shadeform Python SDK available.\n    If no official SDK exists, this function would need to use direct API calls.\n    \"\"\"\n\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    ssh_key_id = None\n\n    with open(public_key_path, 'r', encoding='utf-8') as f:\n        public_key = f.read().strip()\n\n    try:\n        # Add SSH key to Shadeform using our utility functions\n        ssh_key_id = shadeform_adaptor.add_ssh_key_to_shadeform(public_key)\n\n    except ImportError as e:\n        # If required dependencies are missing\n        logger.warning(\n            f'Failed to add Shadeform SSH key due to missing dependencies: '\n            f'{e}. Manually configure SSH keys in your Shadeform account.')\n\n    except Exception as e:\n        logger.warning(f'Failed to set up Shadeform authentication: {e}')\n        raise exceptions.CloudUserIdentityError(\n            'Failed to set up SSH authentication for Shadeform. '\n            f'Please ensure your Shadeform credentials are configured: {e}'\n        ) from e\n\n    if ssh_key_id is None:\n        raise Exception('Failed to add SSH key to Shadeform')\n\n    # Configure SSH info in the config\n    config['auth']['ssh_public_key'] = public_key_path\n    config['auth']['ssh_key_id'] = ssh_key_id\n\n    return configure_ssh_info(config)\n\n\ndef setup_primeintellect_authentication(\n        config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Sets up SSH authentication for Prime Intellect.\n    - Generates a new SSH key pair if one does not exist.\n    - Adds the public SSH key to the user's Prime Intellect account.\n    \"\"\"\n    # Ensure local SSH keypair exists and fetch public key content\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    with open(public_key_path, 'r', encoding='utf-8') as f:\n        public_key = f.read().strip()\n\n    # Register the public key with Prime Intellect (no-op if already exists)\n    client = primeintellect_utils.PrimeIntellectAPIClient()\n    client.get_or_add_ssh_key(public_key)\n\n    # Set up auth section for Ray template\n    config.setdefault('auth', {})\n    # Default username for Prime Intellect images\n    config['auth']['ssh_user'] = 'ubuntu'\n    config['auth']['ssh_public_key'] = public_key_path\n\n    return configure_ssh_info(config)\n\n\ndef setup_seeweb_authentication(config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Registers the public key with Seeweb and notes the remote name.\"\"\"\n    # 1. local key pair\n    auth_utils.get_or_generate_keys()\n\n    # 2. public key\n    _, public_key_path = auth_utils.get_or_generate_keys()\n    with open(public_key_path, 'r', encoding='utf-8') as f:\n        public_key = f.read().strip()\n\n    # 3. Seeweb API client\n    client = seeweb_adaptor.client()\n\n    # 4. Check if key is already registered\n    prefix = f'sky-key-{common_utils.get_user_hash()}'\n    remote_name = None\n    for k in client.fetch_ssh_keys():\n        if k.key.strip() == public_key:\n            remote_name = k.label  # already present\n            break\n\n    # 5. doesn't exist, choose a unique name and create it\n    if remote_name is None:\n        suffix = 1\n        remote_name = prefix\n        existing_names = {k.label for k in client.fetch_ssh_keys()}\n        while remote_name in existing_names:\n            suffix += 1\n            remote_name = f'{prefix}-{suffix}'\n        client.create_ssh_key(label=remote_name, key=public_key)\n\n    # 6. Put the remote name in cluster-config (like for Lambda)\n    config['auth']['remote_key_name'] = remote_name\n\n    return config\n"
        }
    ]
}