{
    "sourceFile": "sky/skylet/constants.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1768543322719,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1768543322719,
            "name": "Commit-0",
            "content": "\"\"\"Constants for SkyPilot.\"\"\"\nfrom typing import List, Tuple\n\nfrom packaging import version\n\nimport sky\nfrom sky.setup_files import dependencies\n\n# The base directory for all SkyPilot runtime artifacts.\n# Historically, we have always used $HOME, but we couldn't\n# do that for Slurm, because $HOME typically points to a NFS\n# mounted directory, which does not work well with SQLite.\n# https://sqlite.org/faq.html#q5\n# Additionally, having the skypilot-runtime python venv be\n# on an NFS makes things very slow.\nSKY_RUNTIME_DIR = '${SKY_RUNTIME_DIR:-$HOME}'\n# Same as above but for use within python code instead of shell commands.\n# Example usage:\n# os.path.join(\n#    os.path.expanduser(os.environ.get(SKY_RUNTIME_DIR_ENV_VAR_KEY, '~')),\n#    '.sky/jobs.db')\nSKY_RUNTIME_DIR_ENV_VAR_KEY = 'SKY_RUNTIME_DIR'\nSKY_CLUSTER_NAME_ENV_VAR_KEY = 'SKY_CLUSTER_NAME'\n# We keep sky_logs and sky_workdir in $HOME, because\n# these are artifacts that users can access, and having\n# them be in $HOME makes it more convenient.\nSKY_LOGS_DIRECTORY = '~/sky_logs'\nSKY_REMOTE_WORKDIR = '~/sky_workdir'\nSKY_TEMPLATES_DIRECTORY = '~/sky_templates'\nSKY_IGNORE_FILE = '.skyignore'\nGIT_IGNORE_FILE = '.gitignore'\n\n# Default Ray port is 6379. Default Ray dashboard port is 8265.\n# Default Ray tempdir is /tmp/ray.\n# We change them to avoid conflicts with user's Ray clusters.\n# We note down the ports in ~/.sky/ray_port.json for backward compatibility.\nSKY_REMOTE_RAY_PORT = 6380\nSKY_REMOTE_RAY_DASHBOARD_PORT = 8266\n# Note we can not use json.dumps which will add a space between \":\" and its\n# value which causes the yaml parser to fail.\nSKY_REMOTE_RAY_PORT_DICT_STR = (\n    f'{{\"ray_port\":{SKY_REMOTE_RAY_PORT}, '\n    f'\"ray_dashboard_port\":{SKY_REMOTE_RAY_DASHBOARD_PORT}}}')\n# The file contains the ports of the Ray cluster that SkyPilot launched,\n# i.e. the PORT_DICT_STR above.\nSKY_REMOTE_RAY_PORT_FILE = '.sky/ray_port.json'\nSKY_REMOTE_RAY_TEMPDIR = '/tmp/ray_skypilot'\nSKY_REMOTE_RAY_VERSION = '2.9.3'\n\n# To avoid user image causing issue with the SkyPilot runtime, we run SkyPilot\n# commands the following prefix:\n# 1. env -u PYTHONPATH: unset PYTHONPATH to avoid any package specified in\n# PYTHONPATH interfering with the SkyPilot runtime.\n# 2. env -C $HOME: set the execution directory to $HOME to avoid the case when\n# a user's WORKDIR in Dockerfile is a Python site-packages directory. Python\n# adds CWD to the beginning of sys.path, so if WORKDIR contains packages (e.g.,\n# compiled for a different Python version), imports will fail with errors like\n# \"ModuleNotFoundError: No module named 'rpds.rpds'\".\n#\n# TODO(zhwu): Switch -C $HOME to PYTHONSAFEPATH=1, once we moved our runtime to\n# Python 3.11 for a more robust setup.\nSKY_UNSET_PYTHONPATH_AND_SET_CWD = 'env -u PYTHONPATH -C $HOME'\n# We store the absolute path of the python executable (/opt/conda/bin/python3)\n# in this file, so that any future internal commands that need to use python\n# can use this path. This is useful for the case where the user has a custom\n# conda environment as a default environment, which is not the same as the one\n# used for installing SkyPilot runtime (ray and skypilot).\nSKY_PYTHON_PATH_FILE = f'{SKY_RUNTIME_DIR}/.sky/python_path'\nSKY_RAY_PATH_FILE = f'{SKY_RUNTIME_DIR}/.sky/ray_path'\nSKY_GET_PYTHON_PATH_CMD = (f'[ -s {SKY_PYTHON_PATH_FILE} ] && '\n                           f'cat {SKY_PYTHON_PATH_FILE} 2> /dev/null || '\n                           'which python3')\n# Python executable, e.g., /opt/conda/bin/python3\nSKY_PYTHON_CMD = (f'{SKY_UNSET_PYTHONPATH_AND_SET_CWD} '\n                  f'$({SKY_GET_PYTHON_PATH_CMD})')\n# Prefer SKY_UV_PIP_CMD, which is faster.\n# TODO(cooperc): remove remaining usage (GCP TPU setup).\nSKY_PIP_CMD = f'{SKY_PYTHON_CMD} -m pip'\n# Ray executable, e.g., /opt/conda/bin/ray\n# We need to add SKY_PYTHON_CMD before ray executable because:\n# The ray executable is a python script with a header like:\n#   #!/opt/conda/bin/python3\nSKY_RAY_CMD = (f'{SKY_PYTHON_CMD} $([ -s {SKY_RAY_PATH_FILE} ] && '\n               f'cat {SKY_RAY_PATH_FILE} 2> /dev/null || which ray)')\n\n# Use $(which env) to find env, falling back to /usr/bin/env if which is\n# unavailable. This works around a Slurm quirk where srun's execvp() doesn't\n# check execute permissions, failing when $HOME/.local/bin/env (non-executable,\n# from uv installation) shadows /usr/bin/env.\nSKY_SLURM_UNSET_PYTHONPATH = ('$(which env 2>/dev/null || echo /usr/bin/env) '\n                              '-u PYTHONPATH')\nSKY_SLURM_PYTHON_CMD = (f'{SKY_SLURM_UNSET_PYTHONPATH} '\n                        f'$({SKY_GET_PYTHON_PATH_CMD})')\n\n# Separate env for SkyPilot runtime dependencies.\nSKY_REMOTE_PYTHON_ENV_NAME = 'skypilot-runtime'\nSKY_REMOTE_PYTHON_ENV: str = f'{SKY_RUNTIME_DIR}/{SKY_REMOTE_PYTHON_ENV_NAME}'\nACTIVATE_SKY_REMOTE_PYTHON_ENV = f'source {SKY_REMOTE_PYTHON_ENV}/bin/activate'\n# Place the conda root in the runtime directory, as installing to $HOME\n# on an NFS takes too long (1-2m slower).\nSKY_CONDA_ROOT = f'{SKY_RUNTIME_DIR}/miniconda3'\n# uv is used for venv and pip, much faster than python implementations.\nSKY_UV_INSTALL_DIR = '\"$HOME/.local/bin\"'\n# set UV_SYSTEM_PYTHON to false in case the\n# user provided docker image set it to true.\n# unset PYTHONPATH in case the user provided docker image set it.\nSKY_UV_CMD = ('UV_SYSTEM_PYTHON=false '\n              f'{SKY_UNSET_PYTHONPATH_AND_SET_CWD} {SKY_UV_INSTALL_DIR}/uv')\n# This won't reinstall uv if it's already installed, so it's safe to re-run.\nSKY_UV_INSTALL_CMD = (f'{SKY_UV_CMD} -V >/dev/null 2>&1 || '\n                      'curl -LsSf https://astral.sh/uv/install.sh '\n                      f'| UV_INSTALL_DIR={SKY_UV_INSTALL_DIR} sh')\nSKY_UV_PIP_CMD: str = (f'VIRTUAL_ENV={SKY_REMOTE_PYTHON_ENV} {SKY_UV_CMD} pip')\nSKY_UV_RUN_CMD: str = (f'VIRTUAL_ENV={SKY_REMOTE_PYTHON_ENV} {SKY_UV_CMD} run '\n                       '--no-project --no-config')\n# Deleting the SKY_REMOTE_PYTHON_ENV_NAME from the PATH and unsetting relevant\n# VIRTUAL_ENV envvars to deactivate the environment. `deactivate` command does\n# not work when conda is used.\nDEACTIVATE_SKY_REMOTE_PYTHON_ENV = (\n    'export PATH='\n    f'$(echo $PATH | sed \"s|$(echo {SKY_REMOTE_PYTHON_ENV})/bin:||\") && '\n    'unset VIRTUAL_ENV && unset VIRTUAL_ENV_PROMPT')\n\n# Prefix for SkyPilot environment variables\nSKYPILOT_ENV_VAR_PREFIX = 'SKYPILOT_'\nSKYPILOT_SERVER_ENV_VAR_PREFIX = 'SKYPILOT_SERVER_'\n\n# The name for the environment variable that stores the unique ID of the\n# current task. This will stay the same across multiple recoveries of the\n# same managed task.\nTASK_ID_ENV_VAR = f'{SKYPILOT_ENV_VAR_PREFIX}TASK_ID'\n# This environment variable stores a '\\n'-separated list of task IDs that\n# are within the same managed job (DAG). This can be used by the user to\n# retrieve the task IDs of any tasks that are within the same managed job.\n# This environment variable is pre-assigned before any task starts\n# running within the same job, and will remain constant throughout the\n# lifetime of the job.\nTASK_ID_LIST_ENV_VAR = f'{SKYPILOT_ENV_VAR_PREFIX}TASK_IDS'\n\n# The version of skylet. MUST bump this version whenever we need the skylet to\n# be restarted on existing clusters updated with the new version of SkyPilot,\n# e.g., when we add new events to skylet, we fix a bug in skylet, or skylet\n# needs to load the new version of SkyPilot code to handle the autostop when the\n# cluster yaml is updated.\n#\n# TODO(zongheng,zhanghao): make the upgrading of skylet automatic?\nSKYLET_VERSION = '30'  # conditional plugin loading for jobs bwcompat\n# The version of the lib files that skylet/jobs use. Whenever there is an API\n# change for the job_lib or log_lib, we need to bump this version, so that the\n# user can be notified to update their SkyPilot version on the remote cluster.\nSKYLET_LIB_VERSION = 4  # add wait_for param to set_autostop\nSKYLET_VERSION_FILE = '.sky/skylet_version'\nSKYLET_LOG_FILE = '.sky/skylet.log'\nSKYLET_PID_FILE = '.sky/skylet_pid'\nSKYLET_PORT_FILE = '.sky/skylet_port'\nSKYLET_GRPC_PORT = 46590\nSKYLET_GRPC_TIMEOUT_SECONDS = 10\n\n# Docker default options\nDEFAULT_DOCKER_CONTAINER_NAME = 'sky_container'\nDEFAULT_DOCKER_PORT = 10022\nDOCKER_USERNAME_ENV_VAR = f'{SKYPILOT_ENV_VAR_PREFIX}DOCKER_USERNAME'\nDOCKER_PASSWORD_ENV_VAR = f'{SKYPILOT_ENV_VAR_PREFIX}DOCKER_PASSWORD'\nDOCKER_SERVER_ENV_VAR = f'{SKYPILOT_ENV_VAR_PREFIX}DOCKER_SERVER'\nDOCKER_LOGIN_ENV_VARS = {\n    DOCKER_USERNAME_ENV_VAR,\n    DOCKER_PASSWORD_ENV_VAR,\n    DOCKER_SERVER_ENV_VAR,\n}\n\nRUNPOD_DOCKER_USERNAME_ENV_VAR = 'SKYPILOT_RUNPOD_DOCKER_USERNAME'\n\n# Commands for disable GPU ECC, which can improve the performance of the GPU\n# for some workloads by 30%. This will only be applied when a user specify\n# `nvidia_gpus.disable_ecc: true` in ~/.sky/config.yaml.\n# Running this command will reboot the machine, introducing overhead for\n# provisioning the machine.\n# https://portal.nutanix.com/page/documents/kbs/details?targetId=kA00e000000LKjOCAW\nDISABLE_GPU_ECC_COMMAND = (\n    # Check if the GPU ECC is enabled. We use `sudo which` to check nvidia-smi\n    # because in some environments, nvidia-smi is not in path for sudo and we\n    # should skip disabling ECC in this case.\n    'sudo which nvidia-smi && echo \"Checking Nvidia ECC Mode\" && '\n    'out=$(nvidia-smi -q | grep \"ECC Mode\" -A2) && '\n    'echo \"$out\" && echo \"$out\" | grep Current | grep Enabled && '\n    'echo \"Disabling Nvidia ECC\" && '\n    # Disable the GPU ECC.\n    'sudo nvidia-smi -e 0 && '\n    # Reboot the machine to apply the changes.\n    '{ sudo reboot || echo \"Failed to reboot. ECC mode may not be disabled\"; } '\n    '|| true; ')\n\nSETUP_SKY_DIRS_COMMANDS = (f'mkdir -p ~/sky_workdir && '\n                           f'mkdir -p ~/.sky/sky_app && '\n                           f'mkdir -p {SKY_RUNTIME_DIR}/.sky;')\n\n# Install conda on the remote cluster if it is not already installed.\n# We use conda with python 3.10 to be consistent across multiple clouds with\n# best effort.\n# https://github.com/ray-project/ray/issues/31606\n# We use python 3.10 to be consistent with the python version of the\n# AWS's Deep Learning AMI's default conda environment.\nCONDA_INSTALLATION_COMMANDS = (\n    'which conda > /dev/null 2>&1 || '\n    '{ '\n    # Use uname -m to get the architecture of the machine and download the\n    # corresponding Miniconda3-Linux.sh script.\n    'curl https://repo.anaconda.com/miniconda/Miniconda3-py310_23.11.0-2-Linux-$(uname -m).sh -o Miniconda3-Linux.sh && '  # pylint: disable=line-too-long\n    # We do not use && for installation of conda and the following init commands\n    # because for some images, conda is already installed, but not initialized.\n    # In this case, we need to initialize conda and set auto_activate_base to\n    # true.\n    '{ '\n    f'bash Miniconda3-Linux.sh -b -p \"{SKY_CONDA_ROOT}\" || true; '\n    f'eval \"$({SKY_CONDA_ROOT}/bin/conda shell.bash hook)\" && conda init && '\n    # Caller should replace {conda_auto_activate} with either true or false.\n    'conda config --set auto_activate_base {conda_auto_activate} && '\n    'conda activate base; }; '\n    # If conda was not installed and the image is a docker image,\n    # we deactivate any active conda environment we set.\n    # Caller should replace {is_custom_docker} with either true or false.\n    'if [ \"{is_custom_docker}\" = \"true\" ]; then '\n    'conda deactivate;'\n    'fi;'\n    '}; '\n    # run this command only if the image is not a docker image assuming\n    # that if a user is using a docker image, they know what they are doing\n    # in terms of conda setup/activation.\n    # Caller should replace {is_custom_docker} with either true or false.\n    'if [ \"{is_custom_docker}\" = \"false\" ]; then '\n    'grep \"# >>> conda initialize >>>\" ~/.bashrc || '\n    '{ conda init && source ~/.bashrc; };'\n    'fi;'\n    # Install uv for venv management and pip installation.\n    f'{SKY_UV_INSTALL_CMD};'\n    # Create a separate python environment for SkyPilot dependencies.\n    f'[ -d {SKY_REMOTE_PYTHON_ENV} ] || '\n    # Do NOT use --system-site-packages here, because if users upgrade any\n    # packages in the base env, they interfere with skypilot dependencies.\n    # Reference: https://github.com/skypilot-org/skypilot/issues/4097\n    # --seed will include pip and setuptools, which are present in venvs created\n    # with python -m venv.\n    # --python 3.10 will ensure the specific python version is downloaded\n    # and installed in the venv. SkyPilot requires Python<3.12, and 3.10 is\n    # preferred. We have to always pass in `--python` to avoid the issue when a\n    # user has `.python_version` file in their home directory, which will cause\n    # uv to use the python version specified in the `.python_version` file.\n    # TODO(zhwu): consider adding --python-preference only-managed to avoid\n    # using the system python, if a user report such issue.\n    f'{SKY_UV_CMD} venv --seed {SKY_REMOTE_PYTHON_ENV} --python 3.10;'\n    f'echo \"$(echo {SKY_REMOTE_PYTHON_ENV})/bin/python\" > {SKY_PYTHON_PATH_FILE};'\n)\n\n_sky_version = str(version.parse(sky.__version__))\nRAY_STATUS = f'RAY_ADDRESS=127.0.0.1:{SKY_REMOTE_RAY_PORT} {SKY_RAY_CMD} status'\nRAY_INSTALLATION_COMMANDS = (\n    f'{SKY_UV_INSTALL_CMD};'\n    f'{SETUP_SKY_DIRS_COMMANDS}'\n    # Print the PATH in provision.log to help debug PATH issues.\n    'echo PATH=$PATH; '\n    # Install setuptools<=69.5.1 to avoid the issue with the latest setuptools\n    # causing the error:\n    #   ImportError: cannot import name 'packaging' from 'pkg_resources'\"\n    f'{SKY_UV_PIP_CMD} install \"setuptools<70\"; '\n    # Backward compatibility for ray upgrade (#3248): do not upgrade ray if the\n    # ray cluster is already running, to avoid the ray cluster being restarted.\n    #\n    # We do this guard to avoid any Ray client-server version mismatch.\n    # Specifically: If existing ray cluster is an older version say 2.4, and we\n    # pip install new version say 2.9 wheels here, then subsequent sky exec\n    # (ray job submit) will have v2.9 vs. 2.4 mismatch, similarly this problem\n    # exists for sky status -r (ray status).\n    #\n    # NOTE: RAY_STATUS will only work for the cluster with ray cluster on our\n    # latest ray port 6380, but those existing cluster launched before #1790\n    # that has ray cluster on the default port 6379 will be upgraded and\n    # restarted.\n    f'{SKY_UV_PIP_CMD} list | grep \"ray \" | '\n    f'grep {SKY_REMOTE_RAY_VERSION} 2>&1 > /dev/null '\n    f'|| {RAY_STATUS} || '\n    # The pydantic-core==2.41.3 for arm seems corrupted\n    # so we need to avoid that specific version.\n    f'{SKY_UV_PIP_CMD} install -U \"ray[default]=={SKY_REMOTE_RAY_VERSION}\" \"pydantic-core==2.41.1\"; '  # pylint: disable=line-too-long\n    # In some envs, e.g. pip does not have permission to write under /opt/conda\n    # ray package will be installed under ~/.local/bin. If the user's PATH does\n    # not include ~/.local/bin (the pip install will have the output: `WARNING:\n    # The scripts ray, rllib, serve and tune are installed in '~/.local/bin'\n    # which is not on PATH.`), causing an empty SKY_RAY_PATH_FILE later.\n    #\n    # Here, we add ~/.local/bin to the end of the PATH to make sure the issues\n    # mentioned above are resolved.\n    f'export PATH=$PATH:{SKY_RUNTIME_DIR}/.local/bin; '\n    # Writes ray path to file if it does not exist or the file is empty.\n    f'[ -s {SKY_RAY_PATH_FILE} ] || '\n    f'{{ {SKY_UV_RUN_CMD} '\n    f'which ray > {SKY_RAY_PATH_FILE} || exit 1; }}; ')\n\n# Copy SkyPilot templates from the installed wheel to ~/sky_templates.\n# This must run after the skypilot wheel is installed.\n# Note: We remove ~/sky_templates first to avoid import conflicts where Python\n# would import from ~/sky_templates instead of site-packages (because\n# sky_templates itself is a package), leading to src == dst error when\n# launching on an existing cluster.\nCOPY_SKYPILOT_TEMPLATES_COMMANDS = (\n    f'rm -rf {SKY_TEMPLATES_DIRECTORY}; '\n    f'{ACTIVATE_SKY_REMOTE_PYTHON_ENV}; '\n    f'{SKY_PYTHON_CMD} -c \\''\n    'import sky_templates, shutil, os; '\n    'src = os.path.dirname(sky_templates.__file__); '\n    f'dst = os.path.expanduser(\\\"{SKY_TEMPLATES_DIRECTORY}\\\"); '\n    'print(f\\\"Copying templates from {src} to {dst}...\\\"); '\n    'shutil.copytree(src, dst); '\n    'print(f\\\"Templates copied successfully\\\")\\'; '\n    # Make scripts executable.\n    f'find {SKY_TEMPLATES_DIRECTORY} -type f ! -name \"*.py\" ! -name \"*.md\" '\n    '-exec chmod +x {} + ; ')\n\nSKYPILOT_WHEEL_INSTALLATION_COMMANDS = (\n    f'{SKY_UV_INSTALL_CMD};'\n    f'{{ {SKY_UV_PIP_CMD} list | grep \"skypilot \" && '\n    '[ \"$(cat ~/.sky/wheels/current_sky_wheel_hash)\" == \"{sky_wheel_hash}\" ]; } || '  # pylint: disable=line-too-long\n    f'{{ {SKY_UV_PIP_CMD} uninstall skypilot; '\n    # uv cannot install azure-cli normally, since it depends on pre-release\n    # packages. Manually install azure-cli with the --prerelease=allow flag\n    # first. This will allow skypilot to successfully install. See\n    # https://docs.astral.sh/uv/pip/compatibility/#pre-release-compatibility.\n    # We don't want to use --prerelease=allow for all packages, because it will\n    # cause uv to use pre-releases for some other packages that have sufficient\n    # stable releases.\n    'if [ \"{cloud}\" = \"azure\" ]; then '\n    f'{SKY_UV_PIP_CMD} install --prerelease=allow \"{dependencies.AZURE_CLI}\";'\n    'fi;'\n    # Install skypilot from wheel\n    f'{SKY_UV_PIP_CMD} install \"$(echo ~/.sky/wheels/{{sky_wheel_hash}}/'\n    f'skypilot-{_sky_version}*.whl)[{{cloud}}, remote]\" && '\n    'echo \"{sky_wheel_hash}\" > ~/.sky/wheels/current_sky_wheel_hash || '\n    'exit 1; }; ')\n\n# Install ray and skypilot on the remote cluster if they are not already\n# installed. {var} will be replaced with the actual value in\n# backend_utils.write_cluster_config.\nRAY_SKYPILOT_INSTALLATION_COMMANDS = (\n    f'{RAY_INSTALLATION_COMMANDS} '\n    f'{SKYPILOT_WHEEL_INSTALLATION_COMMANDS} '\n    # Only patch ray when the ray version is the same as the expected version.\n    # The ray installation above can be skipped due to the existing ray cluster\n    # for backward compatibility. In this case, we should not patch the ray\n    # files.\n    f'{SKY_UV_PIP_CMD} list | grep \"ray \" | '\n    f'grep {SKY_REMOTE_RAY_VERSION} 2>&1 > /dev/null && '\n    f'{{ {SKY_PYTHON_CMD} -c '\n    '\"from sky.skylet.ray_patches import patch; patch()\" || exit 1; }; ')\n\n# The name for the environment variable that stores SkyPilot user hash, which\n# is mainly used to make sure sky commands runs on a VM launched by SkyPilot\n# will be recognized as the same user (e.g., jobs controller or sky serve\n# controller).\nUSER_ID_ENV_VAR = f'{SKYPILOT_ENV_VAR_PREFIX}USER_ID'\n\n# The name for the environment variable that stores SkyPilot user name.\n# Similar to USER_ID_ENV_VAR, this is mainly used to make sure sky commands\n# runs on a VM launched by SkyPilot will be recognized as the same user.\nUSER_ENV_VAR = f'{SKYPILOT_ENV_VAR_PREFIX}USER'\n\n# SSH configuration to allow more concurrent sessions and connections.\n# Default MaxSessions is 10.\n# Default MaxStartups is 10:30:60, meaning:\n#   - Up to 10 unauthenticated connections are allowed without restriction.\n#   - From 11 to 60 connections, 30% are randomly dropped.\n#   - Above 60 connections, all are dropped.\n# These defaults are too low for submitting many parallel jobs (e.g., 150),\n# which can easily exceed the limits and cause connection failures.\n# The new values (MaxSessions 200, MaxStartups 150:30:200) increase these\n# limits significantly.\n# TODO(zeping): Bake this configuration in SkyPilot default images.\nSET_SSH_MAX_SESSIONS_CONFIG_CMD = (\n    'sudo bash -c \\''\n    'echo \"MaxSessions 200\" >> /etc/ssh/sshd_config; '\n    'echo \"MaxStartups 150:30:200\" >> /etc/ssh/sshd_config; '\n    '(systemctl reload sshd || service ssh reload); '\n    '\\'')\n\n# Internal: Env var indicating the system is running with a remote API server.\n# It is used for internal purposes, including the jobs controller to mark\n# clusters as launched with a remote API server.\nUSING_REMOTE_API_SERVER_ENV_VAR = (\n    f'{SKYPILOT_ENV_VAR_PREFIX}USING_REMOTE_API_SERVER')\n\n# In most clouds, cluster names can only contain lowercase letters, numbers\n# and hyphens. We use this regex to validate the cluster name.\nCLUSTER_NAME_VALID_REGEX = '[a-zA-Z]([-_.a-zA-Z0-9]*[a-zA-Z0-9])?'\n\n# Used for translate local file mounts to cloud storage. Please refer to\n# sky/execution.py::_maybe_translate_local_file_mounts_and_sync_up for\n# more details.\nFILE_MOUNTS_BUCKET_NAME = 'skypilot-filemounts-{username}-{user_hash}-{id}'\nFILE_MOUNTS_LOCAL_TMP_DIR = 'skypilot-filemounts-files-{id}'\nFILE_MOUNTS_REMOTE_TMP_DIR = '/tmp/sky-{}-filemounts-files'\n# For API server, the use a temporary directory in the same path as the upload\n# directory to avoid using a different block device, which may not allow hard\n# linking. E.g., in our API server deployment on k8s, ~/.sky/ is mounted from a\n# persistent volume, so any contents in ~/.sky/ cannot be hard linked elsewhere.\nFILE_MOUNTS_LOCAL_TMP_BASE_PATH = '~/.sky/tmp/'\n# Base path for two-hop file mounts translation. See\n# controller_utils.translate_local_file_mounts_to_two_hop().\nFILE_MOUNTS_CONTROLLER_TMP_BASE_PATH = '~/.sky/tmp/controller'\n\n# For passing in CPU and memory limits to the controller pod when running\n# in k8s. Right now, we only use this for the jobs controller, but we may\n# use this for the serve controller as well in the future.\n# These files are written to disk by the skylet, who reads it from env vars\n# passed by the backend when starting the skylet (start_skylet_on_head_node).\nCONTROLLER_K8S_CPU_FILE = '~/.sky/_internal_k8s_pod_cpu'\nCONTROLLER_K8S_MEMORY_FILE = '~/.sky/_internal_k8s_pod_memory'\n\n# Used when an managed jobs are created and\n# files are synced up to the cloud.\nFILE_MOUNTS_WORKDIR_SUBPATH = 'job-{run_id}/workdir'\nFILE_MOUNTS_SUBPATH = 'job-{run_id}/local-file-mounts/{i}'\nFILE_MOUNTS_TMP_SUBPATH = 'job-{run_id}/tmp-files'\n\n# Due to the CPU/memory usage of the controller process launched with sky jobs (\n# use ray job under the hood), we need to reserve some CPU/memory for each jobs/\n# serve controller process.\n# Jobs: A default controller with 8 vCPU and 32 GB memory can manage up to 32\n# managed jobs.\n# Serve: A default controller with 4 vCPU and 16 GB memory can run up to 16\n# services.\nCONTROLLER_PROCESS_CPU_DEMAND = 0.25\n# The log for SkyPilot API server.\nAPI_SERVER_LOGS = '~/.sky/api_server/server.log'\n# The lock for creating the SkyPilot API server.\nAPI_SERVER_CREATION_LOCK_PATH = '~/.sky/api_server/.creation.lock'\n\n# The name for the environment variable that stores the URL of the SkyPilot\n# API server.\nSKY_API_SERVER_URL_ENV_VAR = f'{SKYPILOT_ENV_VAR_PREFIX}API_SERVER_ENDPOINT'\n\n# The name for the environment variable that stores the SkyPilot service\n# account token on client side.\nSERVICE_ACCOUNT_TOKEN_ENV_VAR = (\n    f'{SKYPILOT_ENV_VAR_PREFIX}SERVICE_ACCOUNT_TOKEN')\n\n# SkyPilot environment variables\nSKYPILOT_NUM_NODES = f'{SKYPILOT_ENV_VAR_PREFIX}NUM_NODES'\nSKYPILOT_NODE_IPS = f'{SKYPILOT_ENV_VAR_PREFIX}NODE_IPS'\nSKYPILOT_SETUP_NUM_GPUS_PER_NODE = (\n    f'{SKYPILOT_ENV_VAR_PREFIX}SETUP_NUM_GPUS_PER_NODE')\nSKYPILOT_NUM_GPUS_PER_NODE = f'{SKYPILOT_ENV_VAR_PREFIX}NUM_GPUS_PER_NODE'\nSKYPILOT_NODE_RANK = f'{SKYPILOT_ENV_VAR_PREFIX}NODE_RANK'\n\n# Placeholder for the SSH user in proxy command, replaced when the ssh_user is\n# known after provisioning.\nSKY_SSH_USER_PLACEHOLDER = 'skypilot:ssh_user'\n\nRCLONE_CONFIG_DIR = '~/.config/rclone'\nRCLONE_CONFIG_PATH = f'{RCLONE_CONFIG_DIR}/rclone.conf'\nRCLONE_MOUNT_CACHED_LOG_DIR = '~/.sky/rclone_log'\nRCLONE_CACHE_DIR = '~/.cache/rclone'\nRCLONE_CACHE_REFRESH_INTERVAL = 10\n\n# The keys that can be overridden in the `~/.sky/config.yaml` file. The\n# overrides are specified in task YAMLs.\nOVERRIDEABLE_CONFIG_KEYS_IN_TASK: List[Tuple[str, ...]] = [\n    ('docker', 'run_options'),\n    ('nvidia_gpus', 'disable_ecc'),\n    ('ssh', 'custom_metadata'),\n    ('ssh', 'pod_config'),\n    ('ssh', 'provision_timeout'),\n    ('kubernetes', 'custom_metadata'),\n    ('kubernetes', 'pod_config'),\n    ('kubernetes', 'provision_timeout'),\n    ('kubernetes', 'dws'),\n    ('kubernetes', 'kueue'),\n    ('gcp', 'managed_instance_group'),\n    ('gcp', 'enable_gvnic'),\n    ('gcp', 'enable_gpu_direct'),\n    ('gcp', 'placement_policy'),\n    ('vast', 'datacenter_only'),\n    ('vast', 'create_instance_kwargs'),\n    ('active_workspace',),\n]\n# When overriding the SkyPilot configs on the API server with the client one,\n# we skip the following keys because they are meant to be client-side configs.\n# Also, we skip the consolidation mode config as those should be only set on\n# the API server side.\nSKIPPED_CLIENT_OVERRIDE_KEYS: List[Tuple[str, ...]] = [\n    ('api_server',),\n    ('allowed_clouds',),\n    ('workspaces',),\n    ('db',),\n    ('daemons',),\n    # TODO(kevin,tian): Override the whole controller config once our test\n    # infrastructure supports setting dynamic server side configs.\n    # Tests that are affected:\n    # - test_managed_jobs_ha_kill_starting\n    # - test_managed_jobs_ha_kill_running\n    # - all tests that use LOW_CONTROLLER_RESOURCE_ENV or\n    #   LOW_CONTROLLER_RESOURCE_OVERRIDE_CONFIG (won't cause test failure,\n    #   but the configs won't be applied)\n    ('jobs', 'controller', 'consolidation_mode'),\n    ('serve', 'controller', 'consolidation_mode'),\n    ('jobs', 'controller', 'controller_logs_gc_retention_hours'),\n    ('jobs', 'controller', 'task_logs_gc_retention_hours'),\n]\n\n# Constants for Azure blob storage\nWAIT_FOR_STORAGE_ACCOUNT_CREATION = 60\n# Observed time for new role assignment to propagate was ~45s\nWAIT_FOR_STORAGE_ACCOUNT_ROLE_ASSIGNMENT = 180\nRETRY_INTERVAL_AFTER_ROLE_ASSIGNMENT = 10\nROLE_ASSIGNMENT_FAILURE_ERROR_MSG = (\n    'Failed to assign Storage Blob Data Owner role to the '\n    'storage account {storage_account_name}.')\n\n# Constants for path in K8S pod to store persistent setup and run scripts\n# so that we can run them again after the pod restarts.\n# Path within user home. For HA controller, assumes home directory is\n# persistent through PVC. See kubernetes-ray.yml.j2.\nPERSISTENT_SETUP_SCRIPT_PATH = '~/.sky/.controller_recovery_setup_commands.sh'\nPERSISTENT_RUN_SCRIPT_DIR = '~/.sky/.controller_recovery_task_run'\n# Signal file to indicate that the controller is recovering from a failure.\n# See sky/jobs/utils.py::update_managed_jobs_statuses for more details.\nPERSISTENT_RUN_RESTARTING_SIGNAL_FILE = (\n    '~/.sky/.controller_recovery_restarting_signal')\n\nHA_PERSISTENT_RECOVERY_LOG_PATH = '/tmp/{}ha_recovery.log'\n\n# The placeholder for the local skypilot config path in file mounts for\n# controllers.\nLOCAL_SKYPILOT_CONFIG_PATH_PLACEHOLDER = 'skypilot:local_skypilot_config_path'\n\n# Path to the generated cluster config yamls and ssh configs.\nSKY_USER_FILE_PATH = '~/.sky/generated'\n\n# TODO(cooperc): Update all env vars to begin with SKYPILOT_ or SKYPILOT_SERVER_\n# Environment variable that is set to 'true' if this is a skypilot server.\nENV_VAR_IS_SKYPILOT_SERVER = 'IS_SKYPILOT_SERVER'\nOVERRIDE_CONSOLIDATION_MODE = 'IS_SKYPILOT_JOB_CONTROLLER'\nIS_SKYPILOT_SERVE_CONTROLLER = 'IS_SKYPILOT_SERVE_CONTROLLER'\n# Environment variable that is set to 'true' if rolling update strategy is\n# enabled for the API server deployment.\nSKYPILOT_ROLLING_UPDATE_ENABLED = 'SKYPILOT_ROLLING_UPDATE_ENABLED'\n\nSERVE_OVERRIDE_CONCURRENT_LAUNCHES = (\n    f'{SKYPILOT_ENV_VAR_PREFIX}SERVE_OVERRIDE_CONCURRENT_LAUNCHES')\n\n# Environment variable that is set to 'true' if metrics are enabled.\nENV_VAR_SERVER_METRICS_ENABLED = 'SKY_API_SERVER_METRICS_ENABLED'\n\n# If set, overrides the header that we can use to get the user name.\nENV_VAR_SERVER_AUTH_USER_HEADER = f'{SKYPILOT_ENV_VAR_PREFIX}AUTH_USER_HEADER'\n\n# Environment variable that is used as the DB connection string for the\n# skypilot server.\nENV_VAR_DB_CONNECTION_URI = (f'{SKYPILOT_ENV_VAR_PREFIX}DB_CONNECTION_URI')\n\n# Environment variable that is set to 'true' if basic\n# authentication is enabled in the API server.\nENV_VAR_ENABLE_BASIC_AUTH = 'ENABLE_BASIC_AUTH'\nSKYPILOT_INITIAL_BASIC_AUTH = 'SKYPILOT_INITIAL_BASIC_AUTH'\nSKYPILOT_INGRESS_BASIC_AUTH_ENABLED = 'SKYPILOT_INGRESS_BASIC_AUTH_ENABLED'\nENV_VAR_ENABLE_SERVICE_ACCOUNTS = 'ENABLE_SERVICE_ACCOUNTS'\n\n# Enable debug logging for requests.\nENV_VAR_ENABLE_REQUEST_DEBUG_LOGGING = (\n    f'{SKYPILOT_SERVER_ENV_VAR_PREFIX}ENABLE_REQUEST_DEBUG_LOGGING')\n\nSKYPILOT_DEFAULT_WORKSPACE = 'default'\n\n# BEGIN constants used for service catalog.\nHOSTED_CATALOG_DIR_URL = 'https://raw.githubusercontent.com/skypilot-org/skypilot-catalog/master/catalogs'  # pylint: disable=line-too-long\nHOSTED_CATALOG_DIR_URL_S3_MIRROR = 'https://skypilot-catalog.s3.us-east-1.amazonaws.com/catalogs'  # pylint: disable=line-too-long\nCATALOG_SCHEMA_VERSION = 'v8'\nCATALOG_DIR = '~/.sky/catalogs'\nALL_CLOUDS = ('aws', 'azure', 'gcp', 'ibm', 'lambda', 'scp', 'oci',\n              'kubernetes', 'runpod', 'vast', 'vsphere', 'cudo', 'fluidstack',\n              'paperspace', 'primeintellect', 'do', 'nebius', 'ssh', 'slurm',\n              'hyperbolic', 'seeweb', 'shadeform', 'yotta')\n# END constants used for service catalog.\n\n# The user ID of the SkyPilot system.\nSKYPILOT_SYSTEM_USER_ID = 'skypilot-system'\n\n# The directory to store the logging configuration.\nLOGGING_CONFIG_DIR = '~/.sky/logging'\n\n# Resources constants\nTIME_UNITS = {\n    'm': 1,\n    'h': 60,\n    'd': 24 * 60,\n    'w': 7 * 24 * 60,\n}\n\nTIME_PATTERN: str = ('^[0-9]+('\n                     f'{\"|\".join([unit.lower() for unit in TIME_UNITS])}|'\n                     f'{\"|\".join([unit.upper() for unit in TIME_UNITS])}|'\n                     ')?$')\n\nMEMORY_SIZE_UNITS = {\n    'kb': 2**10,\n    'ki': 2**10,\n    'mb': 2**20,\n    'mi': 2**20,\n    'gb': 2**30,\n    'gi': 2**30,\n    'tb': 2**40,\n    'ti': 2**40,\n    'pb': 2**50,\n    'pi': 2**50,\n}\n\nMEMORY_SIZE_PATTERN = (\n    '^[0-9]+('\n    f'{\"|\".join([unit.lower() for unit in MEMORY_SIZE_UNITS])}|'\n    f'{\"|\".join([unit.upper() for unit in MEMORY_SIZE_UNITS])}|'\n    f'{\"|\".join([unit[0].upper() + unit[1:] for unit in MEMORY_SIZE_UNITS if len(unit) > 1])}'  # pylint: disable=line-too-long\n    ')?$')\n\nLAST_USE_TRUNC_LENGTH = 25\nUSED_BY_TRUNC_LENGTH = 25\n\nMIN_PRIORITY = -1000\nMAX_PRIORITY = 1000\nDEFAULT_PRIORITY = 0\n\nGRACE_PERIOD_SECONDS_ENV_VAR = SKYPILOT_ENV_VAR_PREFIX + 'GRACE_PERIOD_SECONDS'\nCOST_REPORT_DEFAULT_DAYS = 30\n\nENV_VAR_LOOP_LAG_THRESHOLD_MS = (SKYPILOT_ENV_VAR_PREFIX +\n                                 'DEBUG_LOOP_LAG_THRESHOLD_MS')\n\nARM64_ARCH = 'arm64'\nX86_64_ARCH = 'x86_64'\n\nSSH_DISABLE_LATENCY_MEASUREMENT_ENV_VAR = (\n    f'{SKYPILOT_ENV_VAR_PREFIX}SSH_DISABLE_LATENCY_MEASUREMENT')\n"
        }
    ]
}